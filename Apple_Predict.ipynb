{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chienlovecode/Apple_stocks_predict/blob/main/Apple_Predict.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fAJ_vBxjIsjw",
        "outputId": "852bf699-64b9-4185-cf34-2143342793f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.5.1\n"
          ]
        }
      ],
      "source": [
        "#1. Cài đặt thư viện\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import yfinance as yf\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import to_date, col, avg, lag, when\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.ml.feature import VectorAssembler, MinMaxScaler\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "\n",
        "# #2. Khởi tạo SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"StockLSTM_PySpark_AAPL\") \\\n",
        "    .config(\"spark.executor.memory\", \"4g\") \\\n",
        "    .config(\"spark.driver.memory\", \"4g\") \\\n",
        "    .getOrCreate()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Download AAPL data via yfinance and load into Spark\n",
        "START = \"2015-01-01\"\n",
        "TODAY = pd.to_datetime(\"today\").strftime(\"%Y-%m-%d\")\n",
        "\n",
        "# Download into pandas\n",
        "pdf = yf.download('AAPL', START, TODAY).reset_index()\n",
        "\n",
        "# Check if the pandas DataFrame is empty\n",
        "if pdf.empty:\n",
        "    raise ValueError(\"The downloaded data is empty. Check your date range or internet connection.\")\n",
        "\n",
        "# Create Spark DataFrame\n",
        "df_spark = spark.createDataFrame(pdf)\n",
        "df_spark = df_spark.withColumn(\"Date\", to_date(col(\"Date\"), \"yyyy-MM-dd\")).orderBy(\"Date\")\n",
        "df_spark.show(5)"
      ],
      "metadata": {
        "id": "98nTvYgcC3VO",
        "outputId": "bb65bc9c-8244-4187-eff0-246d206f9cca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n",
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['TSLA']: YFRateLimitError('Too Many Requests. Rate limited. Try after a while.')\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "The downloaded data is empty. Check your date range or internet connection.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-99d132fe1701>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Check if the pandas DataFrame is empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The downloaded data is empty. Check your date range or internet connection.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Create Spark DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The downloaded data is empty. Check your date range or internet connection."
          ]
        }
      ]
    }
  ]
}